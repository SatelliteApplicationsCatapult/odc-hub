{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Framework for Near-Real Time Sensor-Agnostic Water Classification**\n",
    "\n",
    "A new image is acquired at T1. Landsat (and potentially Sentinel-2) water masks are aggregated from a period of time T0 (T1-3months). Assuming no significant (TBD) change between T0 and T1 in water extent, it should be possible to identify likely change pixels at the boundary of class distributions if sampled across a representative a large enough area (TBD). Omitting such potential change features enables a significant no. training samples at T1 and these may be used to provide water (+ probability) masks at T1 for all clearsky pixels at T1.\n",
    "\n",
    "Assumptions\n",
    "- At least 'somewhat' a complete water mask can be obtained by generating a water summary product for T0\n",
    "- There is a sufficient area of 'clearsky' within the T1 image\n",
    "- Class transitions are on a sufficiently limited scale that either\n",
    "    - (1) they do not need to be omitted and model selection will be robust enough to treat them as outliers, or\n",
    "    - (2) they can be identified as outliers from the major class distributions using skewness/kurtosis\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://dask-scheduler.dask.svc.cluster.local:8786\n",
       "  <li><b>Dashboard: </b><a href='http://dask-scheduler.dask.svc.cluster.local:8787/status' target='_blank'>http://dask-scheduler.dask.svc.cluster.local:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>5</li>\n",
       "  <li><b>Cores: </b>40</li>\n",
       "  <li><b>Memory: </b>168.65 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.244.4.62:8786' processes=5 cores=40>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Magic + imports likely common across all notebooks\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# Supress Warning \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set reference for util modules\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/odc-hub/')\n",
    "# Generic python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr \n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "import os\n",
    "\n",
    "# sac-specific\n",
    "from sac_utils.createAOI import create_lat_lon\n",
    "\n",
    "# dc-specific\n",
    "from datacube import Datacube\n",
    "from datacube.storage.masking import mask_invalid_data\n",
    "dc = Datacube()\n",
    "from utils_dcal.data_cube_utilities.import_export import export_xarray_to_geotiff\n",
    "\n",
    "# ml stuff\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# dask stuff\n",
    "import dask.array\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "client = Client('dask-scheduler.dask.svc.cluster.local:8786')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **(0) Scope jobs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overall aoi and search criteria to assertain datasets across which to run app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dc.list_measurements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = \"s2_esa_sr_granule\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((-18.317280451285484, -17.376103328077992),\n",
       " (177.47747109686992, 178.74364541327617))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viti_levu = \"POLYGON((177.47747109686992 -17.376103328077992,178.74364541327617 -17.376103328077992,178.74364541327617 -18.317280451285484,177.47747109686992 -18.317280451285484,177.47747109686992 -17.376103328077992))\"\n",
    "# suva = \"POLYGON((178.38384316718242 -18.090287234637962,178.49645303046367 -18.090287234637962,178.49645303046367 -18.181641888359497,178.38384316718242 -18.181641888359497,178.38384316718242 -18.090287234637962))\"\n",
    "# left = \"POLYGON((177.38533176312444 -17.934057815678187,177.52815402874944 -17.934057815678187,177.52815402874944 -18.069888303633736,177.38533176312444 -18.069888303633736,177.38533176312444 -17.934057815678187))\"\n",
    "overall_aoi_wkt = viti_levu\n",
    "overall_aoi_gdf = pd.DataFrame({'geometry':[overall_aoi_wkt]})\n",
    "overall_aoi_gdf['geometry'] = overall_aoi_gdf['geometry'].apply(wkt.loads)\n",
    "overall_aoi_gdf['aoi'] = 'aoi'\n",
    "overall_aoi_gdf = gpd.GeoDataFrame(overall_aoi_gdf, geometry='geometry', crs={\"init\": \"epsg:4326\"}) # using {init} important\n",
    "latitude, longitude = create_lat_lon(overall_aoi_wkt)\n",
    "\n",
    "latitude, longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**find datasets** - *note*: lat lon returns all anti-meridian scenes at that longitude, so need additional filtering here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = dc.find_datasets(\n",
    "    product=product,\n",
    "    lat=latitude,\n",
    "    lon=longitude,\n",
    ") \n",
    "len(ds), # vars(ds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get **ds footprints & dates** - *note*: ds.extent.wkt doesn't play nice so use yml metadata as already in 4326 wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>id</th>\n",
       "      <th>all_meta</th>\n",
       "      <th>geometry</th>\n",
       "      <th>des</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2019-11-20 22:19:41</td>\n",
       "      <td>177.940346</td>\n",
       "      <td>178.983365</td>\n",
       "      <td>-18.174598</td>\n",
       "      <td>-17.174808</td>\n",
       "      <td>ac01a212-4fc8-5a19-8397-a06e4dbc7ed2</td>\n",
       "      <td>Dataset &lt;id=ac01a212-4fc8-5a19-8397-a06e4dbc7e...</td>\n",
       "      <td>POLYGON ((177.9403464638746 -18.17459849994777...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2019-11-20 22:19:41</td>\n",
       "      <td>177.945046</td>\n",
       "      <td>178.993869</td>\n",
       "      <td>-19.078459</td>\n",
       "      <td>-18.078345</td>\n",
       "      <td>0ceeca6c-30d1-5aee-8caf-75b1d803f715</td>\n",
       "      <td>Dataset &lt;id=0ceeca6c-30d1-5aee-8caf-75b1d803f7...</td>\n",
       "      <td>POLYGON ((177.9450459818887 -19.07845942999174...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Date        xmin        xmax       ymin       ymax  \\\n",
       "105 2019-11-20 22:19:41  177.940346  178.983365 -18.174598 -17.174808   \n",
       "104 2019-11-20 22:19:41  177.945046  178.993869 -19.078459 -18.078345   \n",
       "\n",
       "                                       id  \\\n",
       "105  ac01a212-4fc8-5a19-8397-a06e4dbc7ed2   \n",
       "104  0ceeca6c-30d1-5aee-8caf-75b1d803f715   \n",
       "\n",
       "                                              all_meta  \\\n",
       "105  Dataset <id=ac01a212-4fc8-5a19-8397-a06e4dbc7e...   \n",
       "104  Dataset <id=0ceeca6c-30d1-5aee-8caf-75b1d803f7...   \n",
       "\n",
       "                                              geometry   des  \n",
       "105  POLYGON ((177.9403464638746 -18.17459849994777...  True  \n",
       "104  POLYGON ((177.9450459818887 -19.07845942999174...  True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def parsemetaparams(df):\n",
    "    g = []\n",
    "    for index, row in df.iterrows():\n",
    "        g.append(f\"Polygon(({row.xmin} {row.ymin}, {row.xmax} {row.ymin}, {row.xmax} {row.ymax}, {row.xmin} {row.ymax}, {row.xmin} {row.ymin}))\")\n",
    "    df['geometry'] = g\n",
    "    return df\n",
    "df=pd.DataFrame({\n",
    "    'Date': [i.metadata.time[0] for i in ds],\n",
    "    'xmin': [i.metadata.lon[0] for i in ds],\n",
    "    'xmax': [i.metadata.lon[1] for i in ds],\n",
    "    'ymin': [i.metadata.lat[0] for i in ds],\n",
    "    'ymax': [i.metadata.lat[1] for i in ds],\n",
    "    'id': [i.metadata.id for i in ds],\n",
    "    'all_meta': [i for i in ds]\n",
    "})\n",
    "df = parsemetaparams(df)\n",
    "df['geometry'] = df['geometry'].apply(wkt.loads)\n",
    "gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=({\"init\":\"epsg:4326\"}))\n",
    "# repro and intersect to omit potemtial am scenes\n",
    "a = overall_aoi_gdf.to_crs({\"init\": \"epsg:3460\"}) # speed intersect up by repro-ing aoi first\n",
    "gdf['des'] = gdf.to_crs({\"init\": \"epsg:3460\"}).geometry.map(lambda x: x.intersects(a.geometry.any())) # repro and test intersect\n",
    "gdf = gdf[gdf['des']==True] # subset\n",
    "gdf = gdf.sort_values(by=['Date'], ascending=False)\n",
    "\n",
    "# check expected footprints etc.\n",
    "fig, ax = plt.subplots()\n",
    "gdf.to_crs({\"init\": \"epsg:3460\"}).plot(facecolor=\"\",edgecolor=\"b\", ax=ax);\n",
    "overall_aoi_gdf.to_crs({\"init\": \"epsg:3460\"}).plot(facecolor=\"\",edgecolor=\"r\", ax=ax);\n",
    "gdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with just most recent image for now\n",
    "n = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **(0) Set consistent params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-19.08090996444034, -18.08573914510223) (176.9998098839749, 178.0434826969856)\n",
      "('2019-11-20', '2019-11-21') ('2019-08-21', '2019-11-19')\n",
      "red\n"
     ]
    }
   ],
   "source": [
    "# original scene meta for yaml + export later\n",
    "original_metadata = gdf.iloc[[n]]['all_meta'].values[0]\n",
    "# format acquistion date of image being classified\n",
    "T = pd.to_datetime(gdf.iloc[[n]].Date.values[0]).date()\n",
    "# add a day on to satisfy dc.load time range req\n",
    "T1 = (str(T), str(pd.to_datetime(T +pd.DateOffset(1)).date()))\n",
    "# create T0 range of 90 days prior to acquisition\n",
    "T0 = (str(pd.to_datetime(T + pd.DateOffset(-91)).date()), str(pd.to_datetime(T + pd.DateOffset(-1)).date()))\n",
    "# lat and lon taken from image metadate\n",
    "latitude, longitude = create_lat_lon(str(gdf.iloc[[n]].geometry.values[0]))\n",
    "# hopefully fiji crs avoids major AM issues\n",
    "output_crs = \"EPSG:32760\"\n",
    "resolution = (-10,10)\n",
    "ref_channel = 'red'\n",
    "\n",
    "T1_prod = \"s2_esa_sr_granule\"\n",
    "T1_measurements = [\"green\",\"red\",\"blue\",\"nir\",\"swir1\",\"swir2\", \"scene_classification\"]\n",
    "T1_vars = ['green','red','blue','nir','swir1','swir2']\n",
    "\n",
    "print(latitude, longitude)\n",
    "print(T1, T0)\n",
    "print(ref_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **(1) create T0 water mask (T1-3months)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load T0 water masks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 4, x: 11045, y: 11044)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 2019-08-25T22:06:48 ... 2019-09-10T22:06:52\n",
       "  * y        (y) float64 8e+06 8e+06 8e+06 8e+06 ... 7.89e+06 7.89e+06 7.89e+06\n",
       "  * x        (x) float64 5e+05 5e+05 5e+05 ... 6.104e+05 6.104e+05 6.104e+05\n",
       "Data variables:\n",
       "    water    (time, y, x) int16 dask.array<shape=(4, 11044, 11045), chunksize=(1, 1000, 1000)>\n",
       "Attributes:\n",
       "    crs:      EPSG:32760"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = 'ls8_water_classification'\n",
    "measurements = ['water']\n",
    "\n",
    "water_dataset = dc.load(\n",
    "    product=product,\n",
    "    time=T0, # quarter prior to T1 \n",
    "    lat=latitude,\n",
    "    lon=longitude,\n",
    "    output_crs=output_crs,\n",
    "    resolution=resolution,\n",
    "    measurements = measurements,\n",
    "    group_by='solar_day',\n",
    "    dask_chunks={\n",
    "        #'time': 1,\n",
    "        'x': 1000,\n",
    "        'y': 1000,\n",
    "    }\n",
    ")\n",
    "water_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fully **remove nodata** pixels (can't just use ==-9999 due to potential nn averaging within dc.load() at res <native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify pixels with valid data\n",
    "good_quality = (\n",
    "    (water_dataset.water >= 0) # no data\n",
    ")\n",
    "# Apply mask\n",
    "water_dataset = water_dataset.where(good_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**define dask computation** of water summary product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dataset = water_dataset.water.mean(dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**apply computation** to water masks dataset & plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.43 s, sys: 2.48 s, total: 5.91 s\n",
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mean_dataset = mean_dataset.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://dask-scheduler.dask.svc.cluster.local:8786\n",
       "  <li><b>Dashboard: </b><a href='http://dask-scheduler.dask.svc.cluster.local:8787/status' target='_blank'>http://dask-scheduler.dask.svc.cluster.local:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>5</li>\n",
       "  <li><b>Cores: </b>40</li>\n",
       "  <li><b>Memory: </b>168.65 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.244.4.62:8786' processes=5 cores=40>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del water_dataset\n",
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create binary water mask** based on summary product (based off likelihood of being persistent water bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.49 s, sys: 1.24 s, total: 2.73 s\n",
      "Wall time: 2.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "waterpres_prob = 0.5\n",
    "T0_nd_water = np.isnan(mean_dataset)\n",
    "T0_water = mean_dataset.where((mean_dataset < waterpres_prob) | (T0_nd_water == True), 1) # fix > prob to water\n",
    "T0_water = T0_water.where((T0_water >= waterpres_prob) | (T0_nd_water == True), 0) # fix < prob to no water "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **(2) load T1 image**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load** l8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = T1_prod\n",
    "measurements = T1_measurements\n",
    "\n",
    "T1_dataset = dc.load(\n",
    "    product=product,\n",
    "    time=T1, # we know a nice single image is here\n",
    "    lat=latitude,\n",
    "    lon=longitude,\n",
    "    output_crs=output_crs,\n",
    "    resolution=resolution,\n",
    "    measurements = measurements,\n",
    "#     group_by='solar_day',\n",
    "    dask_chunks={\n",
    "        #'time': 1,\n",
    "        'x': 1000,\n",
    "        'y': 1000,\n",
    "    }\n",
    ")\n",
    "# T1_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply **clearsky mask** to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify pixels with valid data\n",
    "if 'usgs' in product:\n",
    "    good_quality = (\n",
    "        (T1_dataset.pixel_qa == 322)  | # clear\n",
    "        (T1_dataset.pixel_qa == 386)  |\n",
    "        (T1_dataset.pixel_qa == 834)  |\n",
    "        (T1_dataset.pixel_qa == 898)  |\n",
    "        (T1_dataset.pixel_qa == 1346) |\n",
    "        (T1_dataset.pixel_qa == 324)  | # water\n",
    "        (T1_dataset.pixel_qa == 388)  |\n",
    "        (T1_dataset.pixel_qa == 836)  |\n",
    "        (T1_dataset.pixel_qa == 900)  |\n",
    "        (T1_dataset.pixel_qa == 1348)\n",
    "    )\n",
    "elif 's2_esa' in product:\n",
    "    good_quality = (\n",
    "    (T1_dataset.scene_classification != 0) & # mask out NO_DATA\n",
    "    (T1_dataset.scene_classification != 1) & # mask out SATURATED_OR_DEFECTIVE\n",
    "    (T1_dataset.scene_classification != 3) & # mask out CLOUD_SHADOWS\n",
    "    (T1_dataset.scene_classification != 8) & # mask out CLOUD_MEDIUM_PROBABILITY\n",
    "    (T1_dataset.scene_classification != 9) & # mask out CLOUD_HIGH_PROBABILITY\n",
    "    (T1_dataset.scene_classification != 10)  # mask out THIN_CIRRUS\n",
    ")\n",
    "\n",
    "# Apply mask\n",
    "T1_dataset = T1_dataset.where(good_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**isolate image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_img = T1_dataset.isel(time = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **(3) Data fusion prep**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3A) Training prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create outside merge of nodata** - T1 img + T0 water mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.43 s, sys: 12.1 ms, total: 4.45 s\n",
      "Wall time: 4.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create mask\n",
    "T0_nd_img = np.isnan(T1_img)[ref_channel]\n",
    "T0_nd = T0_nd_water.where((T0_nd_img == False),True)\n",
    "\n",
    "# apply mask\n",
    "Ytrain = T0_water.where((T0_nd == False))\n",
    "Xtrain = T1_img.where((T0_nd == False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**numpify** T1 image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 green\n",
      "1 red\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "des_vars = T1_vars\n",
    "\n",
    "lenx, leny = np.shape(Xtrain[ref_channel]) # dims of each raster\n",
    "dsvals = np.zeros([len(des_vars),lenx, leny]) #set up array based on shape of xr and no. des bands\n",
    "\n",
    "for i, m in zip(np.arange(0,len(Xtrain.data_vars),1), Xtrain.variables): # loop through bands in xr\n",
    "    print(i, m)\n",
    "    if m in des_vars: # only want relevant channels\n",
    "        vals = np.array(Xtrain[m].values) # extract only the reflectance values\n",
    "        dsvals[i,:,:] = vals # append to 'master' ND array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**re-shape**/flatten T1 data + T0 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = dsvals.reshape(dsvals.shape[0], lenx * leny)  # reshape into nbands x 1D arrays\n",
    "Ytrain = Ytrain.values.flatten()\n",
    "\n",
    "Xtrain.shape, Ytrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**remove coincident nd from arrays** variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.array([i[~np.isnan(i)] for i in Xtrain])\n",
    "Ytrain = Ytrain[~np.isnan(Ytrain)]\n",
    "\n",
    "Xtrain.shape, Ytrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**transpose** variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.transpose()  # transpose so that bands are read as features\n",
    "\n",
    "Xtrain.shape, Ytrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3C) Inference Implementation Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**numpify** T1 image data - within merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "des_vars = ['green','red','blue','nir','swir1','swir2']\n",
    "\n",
    "lenx, leny = np.shape(T1_img[ref_channel]) # dims of each raster\n",
    "dsvals = np.zeros([len(des_vars),lenx, leny]) #set up array based on shape of xr and no. des bands\n",
    "\n",
    "for i, m in zip(np.arange(0,len(T1_img.data_vars),1), T1_img.variables): # loop through bands in xr\n",
    "    print(i, m)\n",
    "    if m in des_vars: # only want relevant channels\n",
    "        vals = np.array(T1_img[m].values) # extract only the reflectance values\n",
    "        dsvals[i,:,:] = vals # append to 'master' ND array\n",
    "# plt.imshow(dsvals[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**re-shape**/flatten T1 data + T1 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ximp = dsvals.reshape(dsvals.shape[0], lenx * leny)  # reshape into nbands x 1D arrays\n",
    "dsvals = None\n",
    "\n",
    "Ximp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**replace coincident nd from arrays** variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**transpose** variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ximp = Ximp.transpose()  # transpose so that bands are read as features\n",
    "\n",
    "Ximp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foundnans = np.isnan(Ximp)\n",
    "Ximp[foundnans] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **(5) Training of T1 using T0 labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define **model params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=10, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt',\n",
    "                               max_depth=2,\n",
    "                               n_jobs=4,\n",
    "                               verbose=2\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fit model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = model.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**score model on training set** - should be replaced with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_score = rf.score(Xtrain, Ytrain)\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract & plot **variable importances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)\n",
    "features = [i for i in T1_img]\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract and **plot decision tree** - TBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **(6) Implement on full T1 image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = rf.predict(Ximp)\n",
    "predicted = np.array(predicted)\n",
    "probability = rf.predict_proba(Ximp)[:, 1]\n",
    "probability = np.array(probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = probability*100\n",
    "probability[foundnans[:,0]] = -9999\n",
    "probability = probability.astype(np.int16)\n",
    "probability = np.reshape(probability, [lenx, leny])\n",
    "\n",
    "predicted = predicted\n",
    "predicted[foundnans[:,0]] = -9999\n",
    "predicted = predicted.astype(np.int16)\n",
    "predicted = np.reshape(predicted, [lenx, leny])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = T1_dataset\n",
    "ds['water_mask'] = (('y','x'), predicted)\n",
    "ds['water_prob'] = (('y','x'), probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(50,50))\n",
    "# # ds.water_mask.plot(ax=ax);\n",
    "# ax.imshow(ds.water_mask.where(ds.water_mask>=0))\n",
    "# ax.set_title('Inferred Water Mask')\n",
    "# fig, ax = plt.subplots(figsize=(50,50))\n",
    "# ax.imshow(ds.water_prob.where(ds.water_prob>=0))\n",
    "# # ds.water_prob.plot(ax=ax);\n",
    "# ax.set_title('Inferred Water Probability')\n",
    "# fig, ax = plt.subplots(figsize=(50,50))\n",
    "# # T1_water.plot(ax=ax);\n",
    "# # ax.imshow(T1_water)\n",
    "# # ax.set_title('Wofs Water Mask')\n",
    "# fig, ax = plt.subplots(figsize=(50,50))\n",
    "# # ds.swir1.where(ds.red>0).plot(ax=ax);\n",
    "# ax.imshow(T1_img.swir1)\n",
    "# ax.set_title('SWIR1 Channel');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **(7) Export(s)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export stuff\n",
    "inter_dir = '/home/jovyan/ml_outputs/water_products/'\n",
    "scene_nm = original_metadata.uris[0].split('/')[-2] # assumes scenename as dir of indexed metadata \n",
    "local_prodir = inter_dir + scene_nm + '/'\n",
    "os.makedirs(local_prodir, exist_ok=True)\n",
    "out_mask_prod = local_prodir + scene_nm + '_watermask.tif'\n",
    "out_prob_prod = local_prodir + scene_nm + '_waterprob.tif'\n",
    "\n",
    "scene_nm, local_prodir, out_mask_prod, out_prob_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "export_xarray_to_geotiff(ds, out_mask_prod, bands=['water_mask'], crs=\"EPSG:3460\", x_coord='x', y_coord='y', no_data=-9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "export_xarray_to_geotiff(ds, out_prob_prod, bands=['water_prob'], crs=\"EPSG:3460\", x_coord='x', y_coord='y', no_data=-9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh /home/jovyan/ml_outputs/water_products/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-04-17 22:30:11'), 'S2A_MSIL2A_20190417T223011_T60KWF')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yaml stuff\n",
    "o_dtme = pd.to_datetime(original_metadata.center_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-04-17'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{T1[0][:4]}_{T1[0][:4]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>des</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2019-04-17 22:30:11</td>\n",
       "      <td>176.999811</td>\n",
       "      <td>178.037982</td>\n",
       "      <td>-18.176925</td>\n",
       "      <td>-17.181809</td>\n",
       "      <td>14366e25-9fce-57e7-8c2e-da6da970b9cf</td>\n",
       "      <td>POLYGON ((176.9998108864126 -18.17692485527006...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date        xmin        xmax       ymin       ymax  \\\n",
       "64 2019-04-17 22:30:11  176.999811  178.037982 -18.176925 -17.181809   \n",
       "\n",
       "                                      id  \\\n",
       "64  14366e25-9fce-57e7-8c2e-da6da970b9cf   \n",
       "\n",
       "                                             geometry   des  \n",
       "64  POLYGON ((176.9998108864126 -18.17692485527006...  True  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.iloc[[n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cubeenv]",
   "language": "python",
   "name": "conda-env-cubeenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

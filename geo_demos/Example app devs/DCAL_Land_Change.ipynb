{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Magic + imports likely common across all notebooks\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# Supress Warning \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set reference for util modules\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/odc-hub/')\n",
    "# Generic python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr \n",
    "\n",
    "# Bonus vector manipulation\n",
    "import pandas as pd\n",
    "#from pandas import Dataframe\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from datetime import datetime\n",
    "\n",
    "CMAP = \"Blues\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Land Change\n",
    "\n",
    "This notebook uses changes in NDVI, EVI or Fractional Cover to identify land change. The algorithm identifies a \"baseline\" and \"analysis\" time period and then compares the spectral parameters in each of those time periods. Significant reductions in vegetation are coincident with land change. In some cases these changes could be deforestation. Users of this algorithm should not accept the accuracy of the results but should conduct ground validation testing to assess accuracy. In most cases, these algorithms can be used to identify clusters of pixels that have experienced change and allow targeted investigation of those areas by local or regional governments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data Cube Configuration\n",
    "import datacube\n",
    "dc = datacube.Datacube(app = 'land_degredation')#, config = '/home/localuser/.datacube.conf')\n",
    "\n",
    "# Import Data Cube API\n",
    "import utils_dcal.data_cube_utilities.data_access_api as dc_api  \n",
    "api = dc_api.DataAccessApi()#config = '/home/localuser/.datacube.conf')\n",
    "dc = api.dc\n",
    "\n",
    "from utils_dcal.data_cube_utilities.dc_display_map import display_map\n",
    "from utils_sac.createAOI import create_lat_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## LS8 Caqueta\n",
    "# Latitude:  (0.000134747292617865, 1.077843593651382)  \n",
    "# Longitude: (-74.91935994831539, -73.30266193148462)  \n",
    "# '2013-04-13', '2018-03-26'\n",
    "# Resolution: (-0.000269494585236, 0.000269494585236)\n",
    "\n",
    "## LS8 Vietnam\n",
    "# Latitude:  (10.513927001104687, 12.611133863411238)  \n",
    "# Longitude: (106.79005909290998, 108.91906631627438)  \n",
    "# '2014-01-14', '2016-12-21'\n",
    "# Resolution: (-0.000269494585236, 0.000269494585236)\n",
    "\n",
    "## LS7 Caqueta\n",
    "# Latitude:  (0.000134747292617865, 1.077843593651382)  \n",
    "# Longitude: (-74.91935994831539, -73.30266193148462)  \n",
    "# '1999-08-21', '2018-03-25'\n",
    "# Resolution: (-0.000269494585236, 0.000269494585236)\n",
    "\n",
    "## LS7 Lake Baringo\n",
    "# Latitude:  (0.4997747685, 0.7495947795)  \n",
    "# Longitude: (35.9742163305, 36.473586859499996)  \n",
    "# '2005-01-08', '2016-12-24'\n",
    "# Resolution: (-0.000269493, 0.000269493)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE >>>>>>>>>>>>>>>>>\n",
    "\n",
    "# Select a Product and Platform\n",
    "#product = ls7_collection1_AMA_ingest\n",
    "#platform = \"LANDSAT_7\"\n",
    "\n",
    "product = 'ls8_usgs_sr_scene'\n",
    "platform = \"LANDSAT_8\"\n",
    "\n",
    "output_crs = \"EPSG:32760\"\n",
    "resolution = (-200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE >>>>>>>>>>>>>>>>>\n",
    "\n",
    "# Select an analysis region (Lat-Lon) within the extents listed above. \n",
    "# HINT: Keep your region small (<0.5 deg square) to avoid memory overload issues\n",
    "# Select a time period (Min-Max) within the extents listed above (Year-Month-Day)\n",
    "# This region and time period will be used for the cloud assessment\n",
    "\n",
    "#Sub-region selection\n",
    "#latitude = (1.0684, 0.8684)\n",
    "#longitude  = (-74.8409, -74.6409)\n",
    "#aoi_wkt = \"POLYGON((178.67520332337 -18.046588897702, 178.68601799012 -18.046588897702, 178.68610382081 -18.057231903073, 178.67537498475 -18.05740356445, 178.67520332337 -18.046588897702))\"\n",
    "aoi_wkt = \"POLYGON ((177.42576599121094 -18.058395415674948, 177.5390625 -18.058395415674948, 177.5390625 -17.96567026450931, 177.42576599121094 -17.96567026450931, 177.42576599121094 -18.058395415674948))\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_extents, lon_extents = create_lat_lon(aoi_wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7f45eb213470>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The code below renders a map that can be used to orient yourself with the region.\n",
    "\n",
    "display_map(latitude = lat_extents, longitude = lon_extents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Analysis Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE >>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# Select the start and end periods for your analysis products\n",
    "# The datetime function is (Year,Month,Day)\n",
    "# These time windows will be used to make a mosaic, so typically pick a year length or more\n",
    "# Be sure to evaluate the RGB mosaics to affirm they are not full of clouds\n",
    "\n",
    "# Select the baseline time period (start and end)\n",
    "baseline_time_period = (datetime(2015,1,1), datetime(2016,1,1))\n",
    "\n",
    "# Select the analysis time period (start and end)\n",
    "analysis_time_period = (datetime(2016,1,1), datetime(2017,1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# Select the cloud-free mosaic type\n",
    "# Options are: max_ndvi, min_ndvi, median, most_recent_pixel, geomedian\n",
    "# If a geomedian is selected, it will take much longer to process\n",
    "# It is most common to use the max_ndvi or median for these land change analyses\n",
    "# HINT: Consider max_ndvi mosaics for NDVI analyses and median mosaics for EVI analyses \n",
    "\n",
    "baseline_mosaic_function = \"median\" \n",
    "analysis_mosaic_function = \"median\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Load Data ( Baseline, Analysis) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "name = \"land change\"\n",
    "version = 1\n",
    "dc = datacube.Datacube(app = \"{}_v{}\".format(name, version))#, #config = '/home/localuser/.datacube.conf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_ds = dc.load(\n",
    "    latitude = lat_extents,\n",
    "    longitude = lon_extents,\n",
    "    time = baseline_time_period,\n",
    "    measurements = [\"red\", \"green\", \"blue\", \"nir\", \"swir1\", \"swir2\", \"pixel_qa\"],\n",
    "    product = product,\n",
    "    platform = platform,                         \n",
    "    output_crs = output_crs,\n",
    "    resolution = resolution\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_ds = dc.load(\n",
    "    latitude = lat_extents,\n",
    "    longitude = lon_extents,\n",
    "    time = analysis_time_period,\n",
    "    measurements = [\"red\", \"green\", \"blue\", \"nir\", \"swir1\", \"swir2\", \"pixel_qa\"],\n",
    "    product = product,\n",
    "    platform = platform,                         \n",
    "    output_crs = output_crs,\n",
    "    resolution = resolution\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Check if loads are valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_dataset_empty(ds:xr.Dataset) -> bool:\n",
    "    checks_for_empty = [\n",
    "                        lambda x: len(x.dims) == 0,      #Dataset has no dimensions\n",
    "                        lambda x: len(x.data_vars) == 0  #Dataset no variables \n",
    "                       ]\n",
    "    for f in checks_for_empty:\n",
    "         if f(ds) == True:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_dataset_empty(baseline_ds): raise Exception(\"DataCube Load returned an empty Dataset.\" +  \n",
    "                                               \"Please check load parameters for Baseline Dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_dataset_empty(analysis_ds): raise Exception(\"DataCube Load returned an empty Dataset.\" +  \n",
    "                                               \"Please check load parameters for Analysis Dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Clean Data\n",
    "> Generating boolean masks that highlight valid pixels\n",
    "> Pixels must be cloud-free over land or water to be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_dcal.data_cube_utilities.dc_mosaic import ls8_unpack_qa, ls7_unpack_qa \n",
    "\n",
    "unpack_function = {\"LANDSAT_7\": ls7_unpack_qa,\n",
    "                   \"LANDSAT_8\": ls8_unpack_qa}\n",
    "\n",
    "unpack = unpack_function[platform]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mask(ds, unpacking_func, bands):\n",
    "    masks = [unpacking_func(ds, band) for band in bands]\n",
    "    return np.logical_or(*masks).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_clean_mask = clean_mask(baseline_ds.pixel_qa,unpack, [\"clear\", \"water\"])\n",
    "analysis_clean_mask = clean_mask(analysis_ds.pixel_qa, unpack, [\"clear\", \"water\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_ds = baseline_ds.where(baseline_clean_mask)\n",
    "analysis_ds = analysis_ds.where(analysis_clean_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Mosaic\n",
    "> Use clean masks in a time series composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils_dcal.data_cube_utilities.dc_mosaic import create_max_ndvi_mosaic, create_min_ndvi_mosaic, create_median_mosaic, create_mosaic, create_hdmedians_multiple_band_mosaic\n",
    "from utils_sac.dc_mosaic import create_max_ndvi_mosaic, create_min_ndvi_mosaic, create_median_mosaic, create_mosaic, create_hdmedians_multiple_band_mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_function = {\"median\": create_median_mosaic,\n",
    "                   \"max_ndvi\": create_max_ndvi_mosaic,\n",
    "                   \"min_ndvi\": create_min_ndvi_mosaic,\n",
    "                   \"geomedian\": create_hdmedians_multiple_band_mosaic,\n",
    "                   \"most_recent_pixel\": create_mosaic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_compositor = mosaic_function[baseline_mosaic_function]\n",
    "analysis_compositor = mosaic_function[analysis_mosaic_function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_composite = baseline_compositor(baseline_ds, clean_mask = baseline_clean_mask)\n",
    "analysis_composite = analysis_compositor(analysis_ds, clean_mask = analysis_clean_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deaAfricascripts.deafrica_plotting import rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb(baseline_composite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb(analysis_composite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## Plot a spectral index using the cloud-filtered mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDVI(dataset):\n",
    "    return (dataset.nir - dataset.red)/(dataset.nir + dataset.red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EVI(dataset):\n",
    "        return 2.5*(dataset.nir - dataset.red)/(dataset.nir + 6.0*dataset.red - 7.5*dataset.blue + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = NDVI(baseline_composite) \n",
    "evi = EVI(baseline_composite)\n",
    "print(baseline_composite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils_dcal.data_cube_utilities.dc_fractional_coverage_classifier import frac_coverage_classify \n",
    "baseline_composite = baseline_composite.rename({\"x\": \"latitude\", \"y\":\"longitude\"})\n",
    "analysis_composite = analysis_composite.rename({\"x\": \"latitude\", \"y\":\"longitude\"})\n",
    "frac_classes = frac_coverage_classify(baseline_composite, clean_mask = np.ones(baseline_composite.pixel_qa.shape).astype(np.bool)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CHANGE HERE >>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# Select a spectral index to plot by removing one of the comment tags (#) below\n",
    "# Adjust the scale of the output using vmin and vmax\n",
    "\n",
    "# (ndvi).plot(figsize=(10,10),cmap = \"Greens\", vmin=0.3, vmax=1.0)\n",
    "#(evi).plot(figsize=(10,10),cmap = \"Greens\", vmin=1.75, vmax=2.5)\n",
    "(frac_classes.pv).plot(figsize=(10,10),cmap = \"Greens\", vmin=70.0, vmax=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE >>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# Select a baseline threshold range for a given parameter ... which is basically a \"mask\"\n",
    "# The analysis will only consider pixels in this range for change detection\n",
    "# No data or cloud pixels will also be masked in this process\n",
    "\n",
    "# If you want to see all change, you should select the full range of values for each parameter\n",
    "# NDVI full range = 0.0 to 1.0\n",
    "# EVI full range = 0.0 to 2.5\n",
    "# Fractional Cover full range = 0.0 to 100.0\n",
    "\n",
    "# If you want to mask out dense vegetation, typical of forested land, use the values below\n",
    "# NDVI: 0.7 to 1.0\n",
    "# EVI: 2.0 to 2.5\n",
    "# Fractional Cover PV: 70.0 to 100.0\n",
    "\n",
    "baseline_threshold_range = (2.00, 2.50) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_min, _max = baseline_threshold_range  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE >>>>>>>>>>>>>\n",
    "\n",
    "# Select the parameter to be used for thresholding ... NDVI, EVI or FC\n",
    "# Remove the comment statement to use the desired parameter\n",
    "\n",
    "# baseline_filter_mask = np.logical_and(NDVI(baseline_composite) > _min, NDVI(baseline_composite) < _max)    \n",
    "baseline_filter_mask = np.logical_and(EVI(baseline_composite) > _min, EVI(baseline_composite) < _max)    \n",
    "# baseline_filter_mask = np.logical_and(frac_classes.pv > _min, frac_classes.pv < _max)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspect_ratio_helper(ds, fixed_width = 12):\n",
    "        y,x = ds.values.shape\n",
    "        width = fixed_width\n",
    "        height = y * (fixed_width / x)\n",
    "        return (width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import RdYlGn, Greens\n",
    "RdYlGn.set_bad('black',1.)\n",
    "Greens.set_bad('black',1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This is the baseline threshold plot that shows GREEN pixels in the threshold range\n",
    "# Pixels with values outside the threshold range are white \n",
    "\n",
    "plt.figure(figsize = aspect_ratio_helper(baseline_filter_mask)) \n",
    "baseline_filter_mask.plot(cmap = \"Greens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_composite = baseline_composite.where(baseline_filter_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Parameter Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_dcal.data_cube_utilities.dc_fractional_coverage_classifier import frac_coverage_classify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE >>>>>>>>>>>>>\n",
    "# Select the parameter to be used for the analysis\n",
    "# You will select two lines for each parameter (baseline and analysis)\n",
    "\n",
    "# Select these two lines for NDVI\n",
    "# parameter_baseline_composite = NDVI(baseline_composite)\n",
    "# parameter_analysis_composite = NDVI(analysis_composite)\n",
    "\n",
    "# Select these two lines for EVI\n",
    "parameter_baseline_composite = EVI(baseline_composite)\n",
    "parameter_analysis_composite = EVI(analysis_composite)\n",
    "\n",
    "# Select these two lines for Fractional Cover (FC)\n",
    "# parameter_baseline_composite = frac_coverage_classify(baseline_composite, clean_mask = np.ones(baseline_composite.pixel_qa.shape).astype(np.bool)) \n",
    "# parameter_analysis_composite = frac_coverage_classify(analysis_composite, clean_mask = np.ones(analysis_composite.pixel_qa.shape).astype(np.bool)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE >>>>>>>>>>>>>\n",
    "\n",
    "# Select this line for NDVI or EVI\n",
    "parameter_anomaly = parameter_analysis_composite - parameter_baseline_composite\n",
    "\n",
    "# Select this line for Fractional Cover (FC), where PV = Photosynthetic Vegetation\n",
    "# parameter_anomaly = parameter_analysis_composite.pv - parameter_baseline_composite.pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the parameter change from the baseline to the analysis period\n",
    "# Significant loss in vegetation will be shown in RED\n",
    "# Gains in vegetation will be shown in GREEN\n",
    "\n",
    "plt.figure(figsize = aspect_ratio_helper(parameter_anomaly)) \n",
    "parameter_anomaly.plot(cmap = RdYlGn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Threshold Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE >>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# Select an Anomaly Threshold Range to filter the results from the previous image\n",
    "# Be sure to put the smallest value in the \"minimum_change\" location (be careful of negative values)\n",
    "\n",
    "# Losses are typically in these ranges for deforestation\n",
    "# NDVI: -0.2 to -0.7\n",
    "# EVI: -0.5 to -1.75\n",
    "# Fractional Cover PV: -20 to -70\n",
    "\n",
    "minimum_change = -1.75\n",
    "maximum_change = -0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a threshold plot using the MIN and MAX range defined above\n",
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "def threshold_plot(da, min_threshold, max_threshold, mask = None, width = 10, *args, **kwargs): \n",
    "    color_in    = np.array([255,0,0])\n",
    "    color_out   = np.array([0,0,0])\n",
    "    color_cloud = np.array([255,255,255])\n",
    "    \n",
    "    array = np.zeros((*da.values.shape, 3)).astype(np.int16)\n",
    "    \n",
    "    inside  = np.logical_and(da.values > min_threshold, da.values < max_threshold)\n",
    "    outside = np.invert(inside)\n",
    "    masked  = np.zeros(da.values.shape).astype(bool) if mask is None else mask\n",
    "    \n",
    "    array[inside] =  color_in\n",
    "    array[outside] = color_out\n",
    "    array[masked] =  color_cloud\n",
    "\n",
    "    def figure_ratio(ds, fixed_width = 10):\n",
    "        width = fixed_width\n",
    "        height = len(ds.latitude) * (fixed_width / len(ds.longitude))\n",
    "        return (width, height)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = figure_ratio(da,fixed_width = width))\n",
    "    \n",
    "    lat_formatter = FuncFormatter(lambda y_val, tick_pos: \"{0:.3f}\".format(da.latitude.values[tick_pos] ))\n",
    "    lon_formatter = FuncFormatter(lambda x_val, tick_pos: \"{0:.3f}\".format(da.longitude.values[tick_pos]))\n",
    "\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter)\n",
    "    \n",
    "    plt.title(\"Threshold: {} < x < {}\".format(min_threshold, max_threshold))\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    \n",
    "    plt.imshow(array, *args, **kwargs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_data_mask = np.logical_or(np.isnan(baseline_composite.red.values), np.isnan(analysis_composite.red.values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the parameter change using thresholds and 3 colors \n",
    "# RED = data in the threshold range (significant land change)\n",
    "# BLACK = data outside the threshold range (no significant change)\n",
    "# WHITE = data outside the baseline mask (not dense vegetation) or clouds (no data)\n",
    "\n",
    "threshold_plot(parameter_anomaly, minimum_change, maximum_change, mask = no_data_mask, width  = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_count(da, min_threshold, max_threshold, mask = None):\n",
    "    def count_not_nans(arr):\n",
    "        return np.count_nonzero(~np.isnan(arr))\n",
    "    \n",
    "    in_threshold = np.logical_and( da.values > min_threshold, da.values < max_threshold)\n",
    "    \n",
    "    total_non_cloudy = count_not_nans(da.values) if mask is None else np.sum(mask) \n",
    "    \n",
    "    return dict(total = np.size(da.values),\n",
    "                total_non_cloudy = total_non_cloudy,\n",
    "                inside = np.nansum(in_threshold),\n",
    "                outside = total_non_cloudy - np.nansum(in_threshold)\n",
    "               )    \n",
    "    \n",
    "def threshold_percentage(da, min_threshold, max_threshold, mask = None):\n",
    "    counts = threshold_count(da, min_threshold, max_threshold, mask = mask)\n",
    "    return dict(percent_inside_threshold = (counts[\"inside\"]   / counts[\"total\"]) * 100.0,\n",
    "                percent_outside_threshold = (counts[\"outside\"] / counts[\"total\"]) * 100.0,\n",
    "                percent_clouds = ( 100.0-counts[\"total_non_cloudy\"] / counts[\"total\"] * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This output is a count of the pixels that fall within each threshold range\n",
    "\n",
    "threshold_count(parameter_anomaly,minimum_change,maximum_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This output is a percentage of the pixels that fall within each threshold range\n",
    "\n",
    "threshold_percentage(parameter_anomaly,minimum_change,maximum_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoTIFF Output Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "def write_geotiff_from_xr(tif_path, data, bands=None, no_data=-9999, crs=\"EPSG:4326\",\n",
    "                          x_coord='longitude', y_coord='latitude'):\n",
    "    \"\"\"Write a geotiff from an xarray dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tif_path: string\n",
    "        The path to write the GeoTIFF file to. You should include the file extension.\n",
    "    x_coord, y_coord: string\n",
    "        The string names of the x and y dimensions.\n",
    "    data: xarray.Dataset or xarray.DataArray\n",
    "    bands: list of string\n",
    "        The bands to write - in the order they should be written.\n",
    "        Ignored if `data` is an `xarray.DataArray`.\n",
    "    no_data: int\n",
    "        The nodata value.\n",
    "    crs: string\n",
    "        The CRS of the output.\n",
    "    \"\"\"\n",
    "    if isinstance(data, xr.DataArray):\n",
    "        height, width = data.sizes[y_coord], data.sizes[x_coord]\n",
    "        count, dtype = 1, data.dtype\n",
    "    else:\n",
    "        if bands is None:\n",
    "            bands = list(data.data_vars.keys())\n",
    "        else:\n",
    "            assrt_msg_begin = \"The `data` parameter is an `xarray.Dataset`. \"\n",
    "            assert isinstance(bands, list), assrt_msg_begin + \"Bands must be a list of strings.\"\n",
    "            assert len(bands) > 0 and isinstance(bands[0], str), assrt_msg_begin + \"You must supply at least one band.\"\n",
    "        height, width = data.dims[y_coord], data.dims[x_coord]\n",
    "        count, dtype = len(bands), data[bands[0]].dtype\n",
    "    with rasterio.open(\n",
    "            tif_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=height,\n",
    "            width=width,\n",
    "            count=count,\n",
    "            dtype=dtype,\n",
    "            crs=crs,\n",
    "            transform=_get_transform_from_xr(data),\n",
    "            nodata=no_data) as dst:\n",
    "        if isinstance(data, xr.DataArray):\n",
    "            dst.write(data.values, 1)\n",
    "        else:\n",
    "            for index, band in enumerate(bands):\n",
    "                dst.write(data[band].values, index + 1)\n",
    "    dst.close()\n",
    "\n",
    "    \n",
    "def _get_transform_from_xr(data, x_coord='longitude', y_coord='latitude'):\n",
    "    \"\"\"Create a geotransform from an xarray.Dataset or xarray.DataArray.\n",
    "    \"\"\"\n",
    "\n",
    "    from rasterio.transform import from_bounds\n",
    "    geotransform = from_bounds(data[x_coord][0], data[y_coord][-1], \n",
    "                               data[x_coord][-1], data[y_coord][0],\n",
    "                               len(data[x_coord]), len(data[y_coord]))\n",
    "    return geotransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE >>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "# Remove the comment tag # to create a GeoTIFF output product\n",
    "# Change the name of the output file, or it will be overwritten for each run \n",
    "# There are 3 possible outputs ... baseline mosaic, analysis mosaic, or anomaly product\n",
    "\n",
    "# write_geotiff_from_xr(\"geotiffs/sample_baseline_01.tif\", bands = ['red','green','blue','nir','swir1','swir2'], baseline_composite)\n",
    "# write_geotiff_from_xr(\"geotiffs/sample_analysis_01.tif\", bands = ['red','green','blue','nir','swir1','swir2'], analysis_composite)\n",
    "# write_geotiff_from_xr(\"geotiffs/sample_anomaly_01.tif\", parameter_anomaly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah geotiffs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cubeenv]",
   "language": "python",
   "name": "conda-env-cubeenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

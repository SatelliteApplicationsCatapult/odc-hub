{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://dask-scheduler.dask.svc.cluster.local:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='http://dask-scheduler.dask.svc.cluster.local:8787/status' target='_blank'>http://dask-scheduler.dask.svc.cluster.local:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>3</li>\n",
       "  <li><b>Cores: </b>24</li>\n",
       "  <li><b>Memory: </b>101.19 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.244.1.165:8786' processes=3 threads=24, memory=101.19 GB>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Magic + imports likely common across all notebooks\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# Supress Warning \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set reference for util modules\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/odc-hub/')\n",
    "# Generic python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Bonus vector manipulation\n",
    "import pandas as pd\n",
    "#from pandas import Dataframe\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "assert(xr.__version__ == \"0.15.0\")\n",
    "assert(dask.__version__ == \"2.12.0\")\n",
    "\n",
    "client = Client('dask-scheduler.dask.svc.cluster.local:8786')\n",
    "\n",
    "client.get_versions(check=True)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dtip fork of datacude_utilities includes some updated requirements which we need for the notebook to run on the updated dask cluster\n",
    "#!pip install git+https://github.com/dtip/datacube-utilities.git#egg=datacube_utilities\n",
    "#!pip install git+https://github.com/SatelliteApplicationsCatapult/datacube-utilities.git#egg=datacube_utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Water Permamency**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required DC utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "# DC utilities\n",
    "from datacube_utilities.dc_display_map import display_map\n",
    "from datacube_utilities.clean_mask import landsat_qa_clean_mask\n",
    "from datacube_utilities.dc_water_classifier import wofs_classify\n",
    "from datacube_utilities.import_export import export_xarray_to_netcdf\n",
    "from datacube_utilities.createAOI import create_lat_lon\n",
    "from datacube.storage import masking\n",
    "from datacube_utilities.clean_mask import lee_filter\n",
    "from datacube_utilities.dc_utilities import write_geotiff_from_xr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define aoi via wkt polygon (could be subbed or shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aoi_wkt = \"POLYGON((178.12 -18.25,178.15 -18.25,178.15 -18.27,178.12 -18.27,178.12 -18.25))\"\n",
    "#testarea\n",
    "#aoi_wkt = \"POLYGON((177.75226467901712 -17.879622210337537,177.80204647833352 -17.879622210337537,177.80204647833352 -17.914988456071715,177.75226467901712 -17.914988456071715,177.75226467901712 -17.879622210337537))\"\n",
    "#aoi_wkt = \"POLYGON((177.75226467901712 -17.879622210337537,177.80204647833352 -17.879622210337537,177.80204647833352 -17.914988456071715,177.75226467901712 -17.914988456071715,177.75226467901712 -17.879622210337537))\"\n",
    "#aoi_wkt = \"POLYGON((177.34673877691375 -17.587272740290974,177.6955546948825 -17.587272740290974,177.6955546948825 -17.800529711996226,177.34673877691375 -17.800529711996226,177.34673877691375 -17.587272740290974))\"\n",
    "#whole country\n",
    "aoi_wkt = \"POLYGON((177.34096527101 -17.746353149414, 177.43160247804 -17.744293212891, 177.4364089966 -17.834930419922, 177.34165191652 -17.833557128906, 177.34096527101 -17.746353149414))\"\n",
    "aoi = gpd.GeoDataFrame(pd.DataFrame({'geoms':[wkt.loads(aoi_wkt)]}), geometry='geoms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set baseline start and end of period\n",
    "start_date = '2018-1-1'\n",
    "end_date = '2018-12-1'\n",
    "res = (30)\n",
    "\n",
    "output_projection = \"EPSG:3460\"\n",
    "crs = \"EPSG:3460\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"water permamency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_chunks=dict(\n",
    "    x=1000,\n",
    "    y=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_extents, lon_extents = create_lat_lon(aoi_wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_map(latitude = lat_extents, longitude = lon_extents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Proj, transform\n",
    "inProj  = Proj(\"+init=EPSG:4326\")\n",
    "outProj = Proj(\"+init=EPSG:3460\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat, max_lat = (lat_extents) \n",
    "min_lon, max_lon = (lon_extents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_A, y_A = transform(inProj, outProj, min_lon, min_lat)\n",
    "x_B, y_B = transform(inProj, outProj, max_lon, max_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_range = (y_A, y_B)\n",
    "lon_range = (x_A, x_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create resolution\n",
    "resolution = (-res, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format dates\n",
    "def createDate(inputStart, inputEnd):\n",
    "    start = datetime.strptime(inputStart, '%Y-%m-%d')\n",
    "    end = datetime.strptime(inputEnd, '%Y-%m-%d')\n",
    "    startDates = start.date()\n",
    "    endDates = end.date()\n",
    "    time_period = (startDates, endDates)\n",
    "    return time_period\n",
    "\n",
    "baseline_time_period = createDate(start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic query specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dict(latitude = lat_range,\n",
    "             longitude = lon_range,\n",
    "             output_crs = output_projection,\n",
    "             crs = crs,\n",
    "             time = baseline_time_period,\n",
    "             resolution = resolution,\n",
    "             group_by = 'solar_day',\n",
    "             dask_chunks = dask_chunks,   \n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset-specifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dsl8' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0fc38d1d1bfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                \u001b[0mmeasurements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"water\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                **query)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdsl8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dsl8' is not defined"
     ]
    }
   ],
   "source": [
    "dsL8 = dc.load(product='ls8_water_classification',\n",
    "               measurements = [\"water\"],\n",
    "               **query)\n",
    "dsl8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_dataset_empty(ds:xr.Dataset) -> bool:\n",
    "    checks_for_empty = [\n",
    "                        lambda x: len(x.dims) == 0,      #Dataset has no dimensions\n",
    "                        lambda x: len(x.data_vars) == 0  #Dataset no variables \n",
    "                       ]\n",
    "    for f in checks_for_empty:\n",
    "         if f(ds) == True:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "waterL8 = dsL8.where(dsL8 != -9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#waterL8_comp = waterL8.compute()\n",
    "water_composite_mean = waterLB.water.mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#water_composite_mean = waterL8_comp.water.mean(dim='time')\n",
    "water_composite_mean = water_composite_mean.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise wofs summary product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8), dpi=120)\n",
    "#waterL8_comp.water.mean(dim='time').plot()\n",
    "water_composite_mean.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_geotiff_from_xr('ls8_water.tiff', water_composite_mean, [\"water\"], crs=output_projection, x_coord = 'x', y_coord = 'y')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cubeenv]",
   "language": "python",
   "name": "conda-env-cubeenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

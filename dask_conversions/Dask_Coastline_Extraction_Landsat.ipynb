{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic + imports likely common across all notebooks\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# Supress Warning \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set reference for util modules\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/odc-hub/')\n",
    "# Generic python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr \n",
    "\n",
    "# Bonus vector manipulation\n",
    "import pandas as pd\n",
    "#from pandas import Dataframe\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from datetime import datetime\n",
    "\n",
    "CMAP = \"Blues\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coastal Erosion Notebook\n",
    "\n",
    "# Under Development\n",
    "\n",
    "## Summary\n",
    "This notebook takes advantage of a time series of Landsat-8 to produce an annual coastline product. \n",
    "\n",
    "## Overview\n",
    "This product is produced, by loading in Landsat-8 data on an annual basis. For each scene a wofs product is produced to identify pixels containing water, as well as cloud and shadows masked. (This step could be replaced in further iterations by using pre-loaded wofs products to increase the computatoinal efficiency). Each scene is matched with it's equivalent tidal height and filtered images within a certain tidal range. Summary annual products are then produced, then shorelines extracted. \n",
    "\n",
    "This notebook takes advantage of DASK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datacube_utilities from git+https://github.com/SatelliteApplicationsCatapult/datacube-utilities.git#egg=datacube_utilities in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (0.0.1)\n",
      "Requirement already satisfied: seaborn==0.9.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (0.9.0)\n",
      "Requirement already satisfied: matplotlib==3.1.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (3.1.0)\n",
      "Requirement already satisfied: geopandas==0.5.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (0.5.0)\n",
      "Requirement already satisfied: scipy==1.3.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (1.3.0)\n",
      "Requirement already satisfied: boto3==1.9.179 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (1.9.179)\n",
      "Requirement already satisfied: datacube==1.7 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (1.7)\n",
      "Requirement already satisfied: ipyleaflet==0.10.8 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (0.10.8)\n",
      "Requirement already satisfied: descartes==1.1.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (1.1.0)\n",
      "Requirement already satisfied: folium==0.9.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (0.9.1)\n",
      "Requirement already satisfied: rasterstats==0.13.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (0.13.1)\n",
      "Requirement already satisfied: ruamel.yaml==0.15.96 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (0.15.96)\n",
      "Requirement already satisfied: scikit-learn==0.21.2 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (0.21.2)\n",
      "Requirement already satisfied: dask==2.0.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (2.0.0)\n",
      "Requirement already satisfied: hdmedians==0.13 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (0.13)\n",
      "Requirement already satisfied: lcmap-pyccd==2017.08.18 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (2017.8.18)\n",
      "Requirement already satisfied: scikit-image==0.15.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (0.15.0)\n",
      "Requirement already satisfied: distributed==2.0.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (2.0.1)\n",
      "Requirement already satisfied: shapely==1.6.4 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube_utilities) (1.6.4)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from seaborn==0.9.0->datacube_utilities) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from seaborn==0.9.0->datacube_utilities) (1.16.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from matplotlib==3.1.0->datacube_utilities) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from matplotlib==3.1.0->datacube_utilities) (2.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from matplotlib==3.1.0->datacube_utilities) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from matplotlib==3.1.0->datacube_utilities) (1.1.0)\n",
      "Requirement already satisfied: pyproj in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from geopandas==0.5.0->datacube_utilities) (2.2.1)\n",
      "Requirement already satisfied: fiona in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from geopandas==0.5.0->datacube_utilities) (1.8.6)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from boto3==1.9.179->datacube_utilities) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.179 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from boto3==1.9.179->datacube_utilities) (1.12.179)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from boto3==1.9.179->datacube_utilities) (0.2.1)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (1.3.5)\n",
      "Requirement already satisfied: toolz in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (0.9.0)\n",
      "Requirement already satisfied: lark-parser>=0.6.7 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (0.8.1)\n",
      "Requirement already satisfied: gdal>=1.9 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (2.4.1)\n",
      "Requirement already satisfied: affine in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (2.2.2)\n",
      "Requirement already satisfied: psycopg2 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (2.8.3)\n",
      "Requirement already satisfied: rasterio>=1.0.2 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (1.0.22)\n",
      "Requirement already satisfied: cloudpickle>=0.4 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (1.2.1)\n",
      "Requirement already satisfied: cachetools in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (3.1.1)\n",
      "Requirement already satisfied: netcdf4 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (1.5.1.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (5.1)\n",
      "Requirement already satisfied: click>=5.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (7.0)\n",
      "Requirement already satisfied: pypeg2 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (2.15.2)\n",
      "Requirement already satisfied: xarray>=0.9 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (0.12.1)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (3.0.1)\n",
      "Requirement already satisfied: singledispatch in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from datacube==1.7->datacube_utilities) (3.4.0.3)\n",
      "Requirement already satisfied: branca<0.4,>=0.3.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from ipyleaflet==0.10.8->datacube_utilities) (0.3.1)\n",
      "Requirement already satisfied: ipywidgets<8,>=7.0.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from ipyleaflet==0.10.8->datacube_utilities) (7.4.2)\n",
      "Requirement already satisfied: traittypes<3,>=0.2.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from ipyleaflet==0.10.8->datacube_utilities) (0.2.1)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from folium==0.9.1->datacube_utilities) (2.10.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from folium==0.9.1->datacube_utilities) (2.22.0)\n",
      "Requirement already satisfied: cligj>=0.4 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from rasterstats==0.13.1->datacube_utilities) (0.5.0)\n",
      "Requirement already satisfied: simplejson in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from rasterstats==0.13.1->datacube_utilities) (3.16.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from scikit-learn==0.21.2->datacube_utilities) (0.13.2)\n",
      "Requirement already satisfied: Cython>=0.23 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from hdmedians==0.13->datacube_utilities) (0.29.15)\n",
      "Requirement already satisfied: click-plugins>=1.0.3 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from lcmap-pyccd==2017.08.18->datacube_utilities) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from scikit-image==0.15.0->datacube_utilities) (2.3)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from scikit-image==0.15.0->datacube_utilities) (6.0.0)\n",
      "Requirement already satisfied: imageio>=2.0.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from scikit-image==0.15.0->datacube_utilities) (2.5.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from scikit-image==0.15.0->datacube_utilities) (1.0.3)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from distributed==2.0.1->datacube_utilities) (2.1.0)\n",
      "Requirement already satisfied: tornado>=5 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from distributed==2.0.1->datacube_utilities) (6.0.3)\n",
      "Requirement already satisfied: psutil>=5.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from distributed==2.0.1->datacube_utilities) (5.6.3)\n",
      "Requirement already satisfied: zict>=0.1.3 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from distributed==2.0.1->datacube_utilities) (1.0.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from distributed==2.0.1->datacube_utilities) (1.12.0)\n",
      "Requirement already satisfied: msgpack in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from distributed==2.0.1->datacube_utilities) (0.6.1)\n",
      "Requirement already satisfied: tblib in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from distributed==2.0.1->datacube_utilities) (1.4.0)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from pandas>=0.15.2->seaborn==0.9.0->datacube_utilities) (2019.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib==3.1.0->datacube_utilities) (41.0.1)\n",
      "Requirement already satisfied: attrs>=17 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from fiona->geopandas==0.5.0->datacube_utilities) (19.1.0)\n",
      "Requirement already satisfied: munch in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from fiona->geopandas==0.5.0->datacube_utilities) (2.3.2)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.179->boto3==1.9.179->datacube_utilities) (1.24.3)\n",
      "Requirement already satisfied: docutils>=0.10 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.179->boto3==1.9.179->datacube_utilities) (0.14)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from rasterio>=1.0.2->datacube==1.7->datacube_utilities) (1.4.6)\n",
      "Requirement already satisfied: cftime in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from netcdf4->datacube==1.7->datacube_utilities) (1.0.3.4)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from jsonschema->datacube==1.7->datacube_utilities) (0.15.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (4.3.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (3.4.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (4.4.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (5.1.1)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (7.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from jinja2>=2.9->folium==0.9.1->datacube_utilities) (1.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from requests->folium==0.9.1->datacube_utilities) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from requests->folium==0.9.1->datacube_utilities) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from requests->folium==0.9.1->datacube_utilities) (2.8)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from networkx>=2.0->scikit-image==0.15.0->datacube_utilities) (4.4.0)\n",
      "Requirement already satisfied: heapdict in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from zict>=0.1.3->distributed==2.0.1->datacube_utilities) (1.0.0)\n",
      "Requirement already satisfied: ipython_genutils in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from traitlets>=4.3.1->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (0.2.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from widgetsnbextension~=3.4.0->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (5.7.8)\n",
      "Requirement already satisfied: jupyter_core in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (4.4.0)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (5.2.4)\n",
      "Requirement already satisfied: pygments in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (2.4.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (4.7.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (0.7.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (0.1.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (2.0.9)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (0.14.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (5.5.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (0.7.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (18.0.2)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (0.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (0.1.7)\n",
      "Requirement already satisfied: parso>=0.3.0 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (0.5.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (3.1.0)\n",
      "Requirement already satisfied: testpath in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (0.4.2)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (0.5.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (1.4.2)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (0.8.4)\n",
      "Requirement already satisfied: webencodings in /opt/conda/envs/cubeenv/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7.0.0->ipyleaflet==0.10.8->datacube_utilities) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/SatelliteApplicationsCatapult/datacube-utilities.git#egg=datacube_utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required DC utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required datacube modules\n",
    "from datacube_utilities.interactive_maps import display_map\n",
    "from datacube_utilities.clean_mask import landsat_qa_clean_mask\n",
    "import datacube_utilities.waterline_functions_deaafrica as waterline_funcs\n",
    "from datacube_utilities.dc_water_classifier import wofs_classify\n",
    "from datacube_utilities.createAOI import create_lat_lon\n",
    "\n",
    "import datacube\n",
    "dc = datacube.Datacube(app='wofs dask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client\n",
    "client = Client('dask-scheduler.dask.svc.cluster.local:8786')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aoi_wkt = \"POLYGON((178.12 -18.25,178.15 -18.25,178.15 -18.27,178.12 -18.27,178.12 -18.25))\"\n",
    "\n",
    "aoi_wkt = \"POLYGON((178.67520332337 -18.046588897702, 178.68601799012 -18.046588897702, 178.68610382081 -18.057231903073, 178.67537498475 -18.05740356445, 178.67520332337 -18.046588897702))\"\n",
    "#aoi_wkt = \"POLYGON((178.68713378906 -17.997493743896, 178.69846343994 -18.00624847412, 178.68301391601 -18.024959564208, 178.67288589477 -18.017063140868, 178.67305755615 -18.017063140868, 178.68713378906 -17.997493743896))\"\n",
    "\n",
    "time_range = (\"2000\", \"2019\")\n",
    "\n",
    "tide_range = (0.00, 10.00)\n",
    "\n",
    "time_step = '1Y'\n",
    "\n",
    "output_projection = \"EPSG:32760\"\n",
    "\n",
    "res = (30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set paths for tide data\n",
    "path = \"/home/shared/geo_demos/tides/\"\n",
    "tide_files = [path + 'IDO70004_2013.csv', path + '/IDO70004_2014.csv', path + '/IDO70004_2015.csv', path + '/IDO70004_2016.csv', path + '/IDO70004_2017.csv', path + '/IDO70004_2018.csv', path + '/IDO70004_2019.csv']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_extents, lon_extents = create_lat_lon(aoi_wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7f5dbd670cf8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waterline_funcs.display_map(latitude=lat_extents, longitude=lon_extents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create resolution\n",
    "resolution = (-res, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_chunks = dict(\n",
    "    x = 1000,\n",
    "    y = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Landsat-8 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'query' dictionary object, which contains the longitudes, latitudes and time provided above\n",
    "query = {\n",
    "    'y': lat_extents,\n",
    "    'x': lon_extents,\n",
    "    'time': time_range,\n",
    "    'output_crs': output_projection,  \n",
    "    'resolution': resolution,\n",
    "    'dask_chunks': dask_chunks\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import L8 scenes for the given period\n",
    "scenes = dc.load(product=\"ls8_water_classification\",\n",
    "                 group_by='solar_day',\n",
    "                 measurements = ['water_classification'],\n",
    "                 **query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'query' dictionary object, which contains the longitudes, \n",
    "# latitudes and time provided above\n",
    "query = {\n",
    "    'y': lat_extents,\n",
    "    'x': lon_extents,\n",
    "    'time': time_range,\n",
    "    #'measurements': ['nbart_red', 'nbart_green', 'nbart_blue', 'nbart_swir_1'],\n",
    "    'resolution': resolution,\n",
    "    'output_crs': output_projection,  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ard(dc,\n",
    "             products=None,\n",
    "             min_gooddata=0.0,\n",
    "             fmask_gooddata=[1, 4, 5],\n",
    "             mask_pixel_quality=True,\n",
    "             mask_invalid_data=True,\n",
    "             mask_contiguity='nbart_contiguity',\n",
    "             mask_dtype=np.float32,\n",
    "             ls7_slc_off=True,\n",
    "             product_metadata=False,\n",
    "             **dcload_kwargs):\n",
    "    '''\n",
    "    Loads Landsat Collection 3 or Sentinel 2 Definitive and Near Real \n",
    "    Time data for multiple sensors (i.e. ls5t, ls7e and ls8c for \n",
    "    Landsat; s2a and s2b for Sentinel 2), and returns a single masked \n",
    "    xarray dataset containing only observations that contain greater \n",
    "    than a given proportion of good quality pixels. This can be used \n",
    "    to extract clean time series of observations that are not affected \n",
    "    by cloud, for example as an input to the `animated_timeseries` \n",
    "    function from `dea_plotting`.\n",
    "    \n",
    "    The proportion of good quality pixels is calculated by summing the \n",
    "    pixels flagged as good quality in `fmask`. By default non-cloudy or \n",
    "    shadowed land, snow and water pixels are treated as good quality, \n",
    "    but this can be customised using the `fmask_gooddata` parameter.\n",
    "    \n",
    "    Last modified: February 2020\n",
    "    \n",
    "    Parameters\n",
    "    ----------  \n",
    "    dc : datacube Datacube object\n",
    "        The Datacube to connect to, i.e. `dc = datacube.Datacube()`.\n",
    "        This allows you to also use development datacubes if required.    \n",
    "    products : list\n",
    "        A list of product names to load data from. Valid options are \n",
    "        ['ga_ls5t_ard_3', 'ga_ls7e_ard_3', 'ga_ls8c_ard_3'] for Landsat,\n",
    "        ['s2a_ard_granule', 's2b_ard_granule'] for Sentinel 2 Definitive, \n",
    "        and ['s2a_nrt_granule', 's2b_nrt_granule'] for Sentinel 2 Near \n",
    "        Real Time (on the DEA Sandbox only).\n",
    "    min_gooddata : float, optional\n",
    "        An optional float giving the minimum percentage of good quality \n",
    "        pixels required for a satellite observation to be loaded. \n",
    "        Defaults to 0.0 which will return all observations regardless of\n",
    "        pixel quality (set to e.g. 0.99 to return only observations with\n",
    "        more than 99% good quality pixels).\n",
    "    fmask_gooddata : list, optional\n",
    "        An optional list of fmask values to treat as good quality \n",
    "        observations in the above `min_gooddata` calculation. The \n",
    "        default is `[1, 4, 5]` which will return non-cloudy or shadowed \n",
    "        land, snow and water pixels. Choose from: \n",
    "        `{'0': 'nodata', '1': 'valid', '2': 'cloud', \n",
    "          '3': 'shadow', '4': 'snow', '5': 'water'}`.\n",
    "    mask_pixel_quality : bool, optional\n",
    "        An optional boolean indicating whether to apply the good data \n",
    "        mask to all observations that were not filtered out for having \n",
    "        less good quality pixels than `min_gooddata`. E.g. if \n",
    "        `min_gooddata=0.99`, the filtered observations may still contain \n",
    "        up to 1% poor quality pixels. The default of False simply \n",
    "        returns the resulting observations without masking out these \n",
    "        pixels; True masks them and sets them to NaN using the good data \n",
    "        mask. This will convert numeric values to floating point values \n",
    "        which can cause memory issues, set to False to prevent this.\n",
    "    mask_invalid_data : bool, optional\n",
    "        An optional boolean indicating whether invalid -999 nodata \n",
    "        values should be replaced with NaN. These invalid values can be\n",
    "        caused by missing data along the edges of scenes, or terrain \n",
    "        effects (for NBART). Be aware that masking out invalid values \n",
    "        will convert all numeric values to floating point values when \n",
    "        -999 values are replaced with NaN, which can cause memory issues.\n",
    "    mask_contiguity : str or bool, optional\n",
    "        An optional string or boolean indicating whether to mask out \n",
    "        pixels missing data in any band (i.e. \"non-contiguous\" values). \n",
    "        Although most missing data issues are resolved by \n",
    "        `mask_invalid_data`, this step is important for generating \n",
    "        clean and concistent composite datasets. The default\n",
    "        is `mask_contiguity='nbart_contiguity'` which will set any \n",
    "        pixels with non-contiguous values to NaN based on NBART data. \n",
    "        If you are loading NBAR data instead, you should specify\n",
    "        `mask_contiguity='nbar_contiguity'` instead. To ignore non-\n",
    "        contiguous values completely, set `mask_contiguity=False`.\n",
    "        Be aware that masking out non-contiguous values will convert \n",
    "        all numeric values to floating point values when -999 values \n",
    "        are replaced with NaN, which can cause memory issues.\n",
    "    mask_dtype : numpy dtype, optional\n",
    "        An optional parameter that controls the data type/dtype that\n",
    "        layers are coerced to when when `mask_pixel_quality=True` or \n",
    "        `mask_contiguity=True`. Defaults to `np.float32`, which uses\n",
    "        approximately 1/2 the memory of `np.float64`.\n",
    "    ls7_slc_off : bool, optional\n",
    "        An optional boolean indicating whether to include data from \n",
    "        after the Landsat 7 SLC failure (i.e. SLC-off). Defaults to \n",
    "        True, which keeps all Landsat 7 observations > May 31 2003. \n",
    "    product_metadata : bool, optional\n",
    "        An optional boolean indicating whether to return the dataset \n",
    "        with a `product` variable that gives the name of the product \n",
    "        that each observation in the time series came from (e.g. \n",
    "        'ga_ls5t_ard_3'). Defaults to False.\n",
    "    **dcload_kwargs : \n",
    "        A set of keyword arguments to `dc.load` that define the \n",
    "        spatiotemporal query used to extract data. This typically\n",
    "        includes `measurements`, `x`, `y`, `time`, `resolution`, \n",
    "        `resampling`, `group_by` and `crs`. Keyword arguments can \n",
    "        either be listed directly in the `load_ard` call like any \n",
    "        other parameter (e.g. `measurements=['nbart_red']`), or by \n",
    "        passing in a query kwarg dictionary (e.g. `**query`). For a \n",
    "        list of possible options, see the `dc.load` documentation: \n",
    "        https://datacube-core.readthedocs.io/en/latest/dev/api/generate/datacube.Datacube.load.html          \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    combined_ds : xarray Dataset\n",
    "        An xarray dataset containing only satellite observations that \n",
    "        contains greater than `min_gooddata` proportion of good quality \n",
    "        pixels.   \n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # Due to possible bug in xarray 0.13.0, define temporary function \n",
    "    # which converts dtypes in a way that preserves attributes\n",
    "    def astype_attrs(da, dtype=np.float32):\n",
    "        '''\n",
    "        Loop through all data variables in the dataset, record \n",
    "        attributes, convert to a custom dtype, then reassign attributes. \n",
    "        If the data variable cannot be converted to the custom dtype \n",
    "        (e.g. trying to convert non-numeric dtype like strings to \n",
    "        floats), skip and return the variable unchanged.\n",
    "        \n",
    "        This can be combined with `.where()` to save memory. By casting \n",
    "        to e.g. np.float32, we prevent `.where()` from automatically \n",
    "        casting to np.float64, using 2x the memory. np.float16 could be \n",
    "        used to save even more memory (although this may not be \n",
    "        compatible with all downstream applications).\n",
    "        \n",
    "        This custom function is required instead of using xarray's \n",
    "        built-in `.astype()`, due to a bug in xarray 0.13.0 that drops\n",
    "        attributes: https://github.com/pydata/xarray/issues/3348\n",
    "        '''\n",
    "        \n",
    "        try:            \n",
    "            da_attr = da.attrs\n",
    "            da = da.astype(dtype)\n",
    "            da = da.assign_attrs(**da_attr)\n",
    "            return da\n",
    "        \n",
    "        except ValueError:        \n",
    "            return da        \n",
    "      \n",
    "\n",
    "    # To prevent modifications to dcload_kwargs being made by this \n",
    "    # function remaining after the function is run (potentially causing \n",
    "    # different results each time the function is run), first take a \n",
    "    # deep copy of the dcload_kwargs object. \n",
    "    dcload_kwargs = deepcopy(dcload_kwargs)  \n",
    "    \n",
    "    # Determine if lazy loading is required\n",
    "    lazy_load = 'dask_chunks' in dcload_kwargs\n",
    "    \n",
    "    # Warn user if they combine lazy load with min_gooddata\n",
    "    if (min_gooddata > 0.0) & lazy_load:\n",
    "                warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n",
    "                              \"will cause dask arrays to compute when \"\n",
    "                              \"loading pixel-quality data to calculate \"\n",
    "                              \"'good pixel' percentage. This can \"\n",
    "                              \"significantly slow the return of your dataset.\")\n",
    "    \n",
    "    # Verify that products were provided, and that only Sentinel-2 or \n",
    "    # only Landsat products are being loaded at the same time\n",
    "    if not products:\n",
    "        raise ValueError(\"Please provide a list of product names \"\n",
    "                         \"to load data from. Valid options are: \\n\"\n",
    "                         \"['ga_ls5t_ard_3', 'ga_ls7e_ard_3', 'ga_ls8c_ard_3'] \" \n",
    "                         \"for Landsat, ['s2a_ard_granule', \"\n",
    "                         \"'s2b_ard_granule'] \\nfor Sentinel 2 Definitive, or \"\n",
    "                         \"['s2a_nrt_granule', 's2b_nrt_granule'] for \"\n",
    "                         \"Sentinel 2 Near Real Time\")\n",
    "    elif all(['ls' in product for product in products]):\n",
    "        product_type = 'ls'\n",
    "    elif all(['s2' in product for product in products]):\n",
    "        product_type = 's2'\n",
    "    else:\n",
    "        raise ValueError(\"Loading both Sentinel-2 and Landsat data \"\n",
    "                         \"at the same time is currently not supported\")\n",
    "\n",
    "    # If `measurements` are specified but do not include fmask or \n",
    "    # contiguity variables, add these to `measurements`\n",
    "    #to_drop = []  # store loaded var names here to later drop\n",
    "    #fmask_band = 'fmask'\n",
    "    \n",
    "    #if 'measurements' in dcload_kwargs:        \n",
    "\n",
    "     #   if fmask_band not in dcload_kwargs['measurements']:\n",
    "          #  dcload_kwargs['measurements'].append(fmask_band)\n",
    "           # to_drop.append(fmask_band)\n",
    "\n",
    "      #  if (mask_contiguity and \n",
    "       #     (mask_contiguity not in dcload_kwargs['measurements'])):\n",
    "        #    dcload_kwargs['measurements'].append(mask_contiguity)\n",
    "         #   to_drop.append(mask_contiguity)  \n",
    "            \n",
    "    # If no `measurements` are specified, Landsat ancillary bands are loaded\n",
    "    # with a 'oa_' prefix, but Sentinel-2 bands are not. As a work-around, \n",
    "    # we need to rename the default contiguity and fmask bands if loading\n",
    "    # Landsat data without specifying `measurements`\n",
    "    #elif product_type == 'ls': \n",
    "        #mask_contiguity = f'oa_{mask_contiguity}' if mask_contiguity else False\n",
    "        #fmask_band = f'oa_{fmask_band}' \n",
    "\n",
    "    # Create a list to hold data for each product\n",
    "    product_data = []\n",
    "\n",
    "    # Iterate through each requested product\n",
    "    for product in products:\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Load data including fmask band\n",
    "            print(f'Loading {product} data')\n",
    "            try:\n",
    "                \n",
    "                # If dask_chunks is specified, load data using query\n",
    "                if lazy_load:\n",
    "                    ds = dc.load(product=f'{product}',\n",
    "                                 **dcload_kwargs)\n",
    "                \n",
    "                # If no dask chunks specified, add this param so that\n",
    "                # we can lazy load data before filtering by good data\n",
    "                else:\n",
    "                    ds = dc.load(product=f'{product}',\n",
    "                                 dask_chunks={},\n",
    "                                 **dcload_kwargs) \n",
    "                \n",
    "            except KeyError as e:\n",
    "                raise ValueError(f'Band {e} does not exist in this product. '\n",
    "                                 f'Verify all requested `measurements` exist '\n",
    "                                 f'in {products}')\n",
    "            \n",
    "            # Keep a record of the original number of observations\n",
    "            total_obs = len(ds.time)\n",
    "            print(total_obs)\n",
    "\n",
    "            # Remove Landsat 7 SLC-off observations if ls7_slc_off=False\n",
    "            #if not ls7_slc_off and product == 'ga_ls7e_ard_3':\n",
    "             #   print('    Ignoring SLC-off observations for ls7')\n",
    "              #  ds = ds.sel(time=ds.time < np.datetime64('2003-05-31'))\n",
    "\n",
    "            # Identify all pixels not affected by cloud/shadow/invalid\n",
    "            good_quality = ds\n",
    "            \n",
    "            # The good data percentage calculation has to load in all `fmask`\n",
    "            # data, which can be slow. If the user has chosen no filtering \n",
    "            # by using the default `min_gooddata = 0`, we can skip this step \n",
    "            # completely to save processing time\n",
    "            #if min_gooddata > 0.0:\n",
    "\n",
    "                # Compute good data for each observation as % of total pixels\n",
    "             #   data_perc = (good_quality.sum(axis=1).sum(axis=1) / \n",
    "              #      (good_quality.shape[1] * good_quality.shape[2]))\n",
    "\n",
    "                # Filter by `min_gooddata` to drop low quality observations\n",
    "#                ds = ds.sel(time=data_perc >= min_gooddata)\n",
    " #               print(f'    Filtering to {len(ds.time)} '\n",
    "  #                    f'out of {total_obs} observations')\n",
    "                \n",
    "            # If any data was returned\n",
    "            if len(ds.time) > 0:\n",
    "\n",
    "                # Optionally apply pixel quality mask to observations \n",
    "                # remaining after the filtering step above to mask out \n",
    "                # all remaining bad quality pixels\n",
    "                if mask_pixel_quality:\n",
    "                    print('    Applying pixel quality/cloud mask')\n",
    "\n",
    "                    # Change dtype to custom float before masking to \n",
    "                    # save memory. See `astype_attrs` func docstring \n",
    "                    # above for details  \n",
    "                    ds = ds.apply(astype_attrs, \n",
    "                                  dtype=mask_dtype, \n",
    "                                  keep_attrs=True)\n",
    "                    ds = ds.where(good_quality)\n",
    "                    \n",
    "                # Optionally filter to replace no data values with nans\n",
    "                if mask_invalid_data:\n",
    "                    print('    Applying invalid data mask')\n",
    "\n",
    "                    # Change dtype to custom float before masking to \n",
    "                    # save memory. See `astype_attrs` func docstring \n",
    "                    # above for details           \n",
    "                    ds = ds.apply(astype_attrs, \n",
    "                                  dtype=mask_dtype, \n",
    "                                  keep_attrs=True)\n",
    "                    ds = masking.mask_invalid_data(ds)\n",
    "\n",
    "                # Optionally apply contiguity mask to observations to\n",
    "                # remove pixels missing data in any band\n",
    "                #if mask_contiguity:\n",
    "                #    print('    Applying contiguity mask')\n",
    "\n",
    "                    # Change dtype to custom float before masking to \n",
    "                    # save memory. See `astype_attrs` func docstring \n",
    "                    # above for details   \n",
    "                 #   ds = ds.apply(astype_attrs, \n",
    "                  #                dtype=mask_dtype, \n",
    "                   #               keep_attrs=True)                    \n",
    "                    #ds = ds.where(ds[mask_contiguity] == 1)   \n",
    "\n",
    "                # Optionally add satellite/product name as a new variable\n",
    "                #if product_metadata:\n",
    "                 #   ds['product'] = xr.DataArray(\n",
    "                  #      [product] * len(ds.time), [('time', ds.time)])\n",
    "\n",
    "                # If any data was returned, add result to list\n",
    "                product_data.append(ds)\n",
    "               \n",
    "            # If no data is returned, print status\n",
    "            else:\n",
    "                print(f'    No data for {product}')\n",
    "                \n",
    "\n",
    "            # If  AttributeError due to there being no variables in\n",
    "            # the dataset, skip this product and move on to the next\n",
    "        except AttributeError:\n",
    "            print(f'    No data for {product}')\n",
    "               # If any data was returned above, combine into one xarray\n",
    "    if (len(product_data) > 0):\n",
    "        # Concatenate results and sort by time\n",
    "        print(f'Combining and sorting data')\n",
    "        combined_ds = xr.concat(product_data, dim='time').sortby('time')\n",
    "        \n",
    "        # If `lazy_load` is True, return data as a dask array without\n",
    "        # actually loading it in\n",
    "        if lazy_load:\n",
    "            print(f'    Returning {len(combined_ds.time)} observations'' as a dask array')\n",
    "            return combined_ds\n",
    "        else:\n",
    "            print(f'    Returning {len(combined_ds.time)} observations ')\n",
    "            return combined_ds.compute()\n",
    "\n",
    "            # If no data was returned:\n",
    "    else:\n",
    "        print('No data returned for query')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ls8_water_classification data\n",
      "283\n",
      "Loading ls7_water_classification data\n",
      "312\n",
      "Loading ls5_water_classification data\n",
      "    No data for ls5_water_classification\n",
      "Loading ls4_water_classification data\n",
      "    No data for ls4_water_classification\n",
      "Combining and sorting data\n",
      "    Returning 595 observations as a dask array\n"
     ]
    }
   ],
   "source": [
    "# Load available data from all three Landsat satellites\n",
    "#from datacube_utilities.dea_datahandling import load_ard\n",
    "landsat_ds = load_ard(dc=dc,\n",
    "                      products=['ls8_water_classification', \n",
    "                                'ls7_water_classification',\n",
    "                                'ls5_water_classification',\n",
    "                                'ls4_water_classification'],\n",
    "                      group_by='solar_day',\n",
    "                      mask_invalid_data=False,\n",
    "                      mask_pixel_quality=False,\n",
    "                      dask_chunks = {},\n",
    "                      **query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#water_classes.isel(time = 4).water_classification.plot();\n",
    "water_classes = dask.delayed(landsat_ds.where(landsat_ds >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_classes_comp = water_classes.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(water_classes_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply wofs classifier from utils. \n",
    "#clearsky_masks = landsat_qa_clean_mask(scenes, 'LANDSAT_8')\n",
    "#clearsky_scenes = scenes.where(clearsky_masks)\n",
    "#water_classes = wofs_classify(scenes, clean_mask=clearsky_masks.values , no_data = np.nan , x_coord='x', y_coord = \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot an example scene\n",
    "#wc_l8.isel(time = 1).wofs.plot(cmap='RdBu');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import tide height data \n",
    "Into pandas and concatenate each year together.\n",
    "\n",
    "Shoreline location varies with tides, only tide heights at specific conditions are kept - determined by tide_range setting. If tide_range values at 0.00, 2.00 then only tides between 0 and 2m relative to Mean Sea Level are kept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data here comes from http://www.bom.gov.au/oceanography/projects/spslcmp/data/index.shtml for fiji\n",
    "\n",
    "year_files = []\n",
    "for f in tide_files:\n",
    "    tide_data = pd.read_csv(f, parse_dates=['time'], index_col='time')\n",
    "    year_files.append(tide_data)\n",
    "    \n",
    "tide_data = pd.concat(year_files)\n",
    "print(tide_data.head())\n",
    "#tide_data_2013 = pd.read_csv(tide_file_2013, parse_dates=['time'], index_col='time')\n",
    "#tide_data_2017 = pd.read_csv(tide_file_2017, parse_dates=['time'], index_col='time')\n",
    "#tide_data_2018 = pd.read_csv(tide_file_2018, parse_dates=['time'], index_col='time')\n",
    "#tide_data_2013['tide'] = tide_data_2013['Sea Level']\n",
    "#tide_data_2016 = pd.read_csv(tide_file_2016, parse_dates= ['time'], index_col=\"time\")\n",
    "#tide_data = pd.concat([tide_data_2013, tide_data_2017])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_data['tide_height'] = tide_data['tide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we convert the data to an xarray dataset so we can analyse it in the same way as our Landsat data\n",
    "tide_data_xr = tide_data.to_xarray()\n",
    "\n",
    "# We want to convert our hourly tide heights to estimates of exactly how high the tide was at the time that\n",
    "# each satellite image was taken. To do this, we can use `.interp` to 'interpolate' a tide height for each\n",
    "# Landsat timestamp:\n",
    "\n",
    "landsat_tideheights = tide_data_xr.interp(time=water_classes_comp.time)\n",
    "\n",
    "# We then want to put these values back into the Landsat dataset so that each image has an estimated tide height:\n",
    "water_classes_comp['tide_height'] = landsat_tideheights.tide_height\n",
    "\n",
    "# Plot the resulting tide heights for each Landsat image:\n",
    "water_classes_comp.tide_height.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Landsat Images by tide height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep the Landsat Images which correspond to the desired tide height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_hightide = water_classes_comp.where((water_classes_comp.tide_height > tide_range[0]) & \n",
    "                                   (water_classes_comp.tide_height < tide_range[1]), drop=True)\n",
    "landsat_hightide.water.isel(time=3).plot(cmap='YlOrRd', size=6, vmin=-0.5, vmax=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Summary Images of Water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_resampled = landsat_hightide.water.compute().resample(time=time_step).max('time')\n",
    "landsat_resampled.plot(col='time', cmap='RdBu', col_wrap=3, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert values to binary based on threshold of 0.5\n",
    "for i in landsat_resampled.values:\n",
    "    np.where(i < 0.5, i, 0*i)\n",
    "    np.where(i >= 0.5, i, 0*i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Shorelines from Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up attributes to assign to each waterline\n",
    "attribute_data = {'time': [str(i)[0:10] for i in landsat_resampled.time.values]}\n",
    "attribute_dtypes = {'time': 'str'}\n",
    "\n",
    "contour_gdf = waterline_funcs.contour_extract(\n",
    "    z_values=[0.8],\n",
    "    ds_array=landsat_resampled,\n",
    "    ds_crs=scenes.crs,\n",
    "    ds_affine=scenes.geobox.transform,\n",
    "    output_shp=f'output_waterlines.shp',\n",
    "    attribute_data=attribute_data,\n",
    "    attribute_dtypes=attribute_dtypes,\n",
    "    min_vertices=5\n",
    ")\n",
    "\n",
    "# Plot output shapefile over the top of the first year's MNDWI layer\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 7))\n",
    "landsat_resampled.isel(time=-1).plot(ax=ax, cmap='Greys', alpha=1.0, edgecolors=None)\n",
    "contour_gdf.plot(cmap='YlOrRd', ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(contour_gdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Interactive map of output shorelines coloured by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterline_funcs.map_shapefile(gdf=contour_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour = contour_gdf[3:4]\n",
    "waterline_funcs.map_shapefile(gdf=contour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour1 = contour_gdf[1:2]\n",
    "print(contour1)\n",
    "waterline_funcs.map_shapefile(gdf=contour1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour1 = contour_gdf[0:1]\n",
    "print(contour1)\n",
    "waterline_funcs.map_shapefile(gdf=contour1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cubeenv]",
   "language": "python",
   "name": "conda-env-cubeenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
